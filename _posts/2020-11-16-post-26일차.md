---
title: "인공지능_자연어처리_3_26일차"
categories:
  - AI
tags:
  - AI
  - NLP
---

## 인공지능 자연어처리 3 (26일차)

### 어탠션.

Encoder 에 있는 모든 문장이 hs 에 담겨서 Decoder 가 받아서
사용한다.
이때 요령은 hs의 마지막 것을 LSTM 에 넣는 것이고,
나머지 hs 전체는 어떤 계산을 통해 Affine 층으로 넘기자..

어떤 계산을 두단계로 했다.
hs 중 확률 a를 알 수 있다면 선택한 확률은 미분을 적용할 수 없으니
가중합을 계산하여 맥락 백터를 구한다.
이 층을 만들기 위해 기술적인 문제가 있는데... 이것을 세로로 리쉐이빙하고(reshape)
그 뒤 repeat 하는 것인데.. 파이썬에는 브로드캐스트가 있어서
사용하면 되지만, repeat 하는 것을 사용하는게 수학적으로 들어나기 때문에
repeat을 하는게 더 좋다.


소스8_1
weightSum 에서
hs의 모든 행과 ar의 행이 곱해져서 행이 선택되는 구조이다.
c를 affine 층으로 넘기는 것이다.

소스8_3
시각화 하는 소스.

### 양방향 RNN

### seq2seq 심층화와 skip 연결
LSTM 계층의 skip 연결 한 값을 추가 하여 손실없는 값도 위쪽으로 보내서
비교하는 방법이다.

**병렬처리를 하기 어려운 단점이 있는게 RNN이다.
